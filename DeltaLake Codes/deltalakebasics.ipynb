{"cells":[{"cell_type":"markdown","source":["##Creating a table from dummy data and saving it in delta table format"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"276b0965-5c25-43a7-bc97-dbd8dd675b45","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = spark.range(0,5)\ndata.write.format('delta').save('/tmp/delta-table')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6bd60c1e-6d96-4031-b7c6-a2b3b532dcbe","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Reading the data from saved delta table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7153ac3-ab5e-4ed2-bad3-c2de030d9f48","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df = spark.read.format('delta').load('/tmp/delta-table')\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae598138-373c-48d3-8a72-20a917184b42","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Modifying the eisting delta table with new values"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b42dd835-9bda-4fe7-8932-e625c8ae6314","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["data = spark.range(5, 10)\ndata.write.format('delta').mode('overwrite').save('/tmp/delta-table')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85cfa5a5-8034-4fd2-bcfe-c8df1c6faff3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Conditionally updating the data without overwriting\nUsing Delta Lake APIs to conditionally update, delete and merging data into tables."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e749b2ed-aded-42d7-932f-7f1bf801bc0d","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from delta.tables import *\nfrom pyspark.sql.functions import *\n\ndeltaTable = DeltaTable.forPath(spark, \"/tmp/delta-table\")\n\n# Update every even value by adding 100 to it\ndeltaTable.update(\n  condition = expr(\"id % 2 == 0\"),\n  set = { \"id\": expr(\"id + 100\") })\n\n# Delete every even value\ndeltaTable.delete(condition = expr(\"id % 2 == 0\"))\n\n# Upsert (merge) new data\nnewData = spark.range(0, 20)\n\ndeltaTable.alias(\"oldData\") \\\n  .merge(\n    newData.alias(\"newData\"),\n    \"oldData.id = newData.id\") \\\n  .whenMatchedUpdate(set = { \"id\": col(\"newData.id\") }) \\\n  .whenNotMatchedInsert(values = { \"id\": col(\"newData.id\") }) \\\n  .execute()\n\ndeltaTable.toDF().show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eae198c1-b8a8-40f6-94fe-78377731da40","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+\n| id|\n+---+\n|  2|\n|  3|\n|  4|\n|  7|\n|  8|\n|  9|\n| 12|\n| 13|\n| 14|\n| 17|\n| 18|\n| 19|\n|  0|\n|  1|\n|  5|\n|  6|\n| 10|\n| 11|\n| 15|\n| 16|\n+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+\n| id|\n+---+\n|  2|\n|  3|\n|  4|\n|  7|\n|  8|\n|  9|\n| 12|\n| 13|\n| 14|\n| 17|\n| 18|\n| 19|\n|  0|\n|  1|\n|  5|\n|  6|\n| 10|\n| 11|\n| 15|\n| 16|\n+---+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Reading the older version of data using time travel\nWe can query previous snapshots of your Delta table by using time travel"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"64ca9aa3-858d-4909-8bce-898db4931e75","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df = spark.read.format(\"delta\") \\\n  .option(\"versionAsOf\", 0) \\\n  .load(\"/tmp/delta-table\")\n\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5a1345c8-7a20-4cfb-8bbe-21ac29dc4c34","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+\n| id|\n+---+\n|  0|\n|  1|\n|  2|\n|  3|\n|  4|\n+---+\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Writing stream of data into a table.\nWe can also write to a Delta table using Structured Streaming. The Delta Lake transaction log guarantees exactly-once processing, even when there are other streams or batch queries running concurrently against the table. By default, streams run in append mode, which adds new records to the table:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fada9183-3dc2-4e61-97d2-eafbcc94f2be","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["streamingDf = spark.readStream.format(\"rate\").load()\n\nstream = streamingDf \\\n  .selectExpr(\"value as id\") \\\n  .writeStream.format(\"delta\") \\\n  .option(\"checkpointLocation\", \"/tmp/checkpoint\") \\\n  .start(\"/tmp/delta-table\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7a7b247b-7976-4f50-9c3e-5c693d487bc8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Stopping the streaming data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"8b0a05f2-14f0-4aa8-b421-d4dcd7138d02","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["stream.stop()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"33682910-dd0c-4a0c-9891-ea1eb24fe656","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Reading stream of data from a table.\nWhile the stream is writing to the Delta table, we can also read from that table as streaming source. For example, we can start another streaming query that prints all the changes made to the Delta table. We can specify which version Structured Streaming should start from by providing the startingVersion or startingTimestamp option to get changes from that point onwards."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90473dd4-e2bb-4579-a27b-7c282539996c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["stream2 = spark.readStream.format(\"delta\") \\\n  .load(\"/tmp/delta-table\") \\\n  .writeStream.format(\"console\") \\\n  .start()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"33642fbf-cee0-4f95-8890-0a9bc611e84b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Again, stopping the streaming data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0c8c33bd-9e20-416f-902d-ec520ccff63a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["stream2.stop()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0de73454-cf0d-4adc-89fd-3b5439359c6c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"02a4422b-6513-41db-8b10-bdbe80dea4c7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"deltalakebasics","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3413067093425864}},"nbformat":4,"nbformat_minor":0}
